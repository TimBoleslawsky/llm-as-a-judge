\section{Introduction}
Large Language Models (LLMs) have become increasingly central to automated code generation and evaluation tasks. Their ability to both produce solutions and assess responses has opened new research avenues, but also raised questions about reliability, bias, and alignment with human judgment. A crucial research strand focuses on \textit{LLMs as a judge}. The evaluation of Large Language Model (LLM) outputs increasingly relies on \emph{LLMs-as-Judges} to approximate human quality judgments across diverse tasks \cite{li2024_llmsasjudges, zheng2023judgelm, bavaresco2024judgebench}. 